---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

vars:
  TALOS_MACHINE_FILE: '{{.TALOS_DIR}}/machineconfig.yaml.j2'

tasks:
  apply-node:
    desc: Apply Talos config to a node [CLUSTER=main] [NODE=required] [MODE=auto]
    cmd: |-
      minijinja-cli {{.TALOS_DIR}}/machineconfig.yaml.j2 | op inject \
        | talosctl --nodes {{.NODE}} apply-config \
          --mode {{.MODE}} \
          --config-patch @{{.TALOS_DIR}}/{{.MACHINE_TYPE}}/{{.NODE}}.yaml \
          --file /dev/stdin {{if .INSECURE}}--insecure{{end}} \
          --talosconfig {{.TALOS_DIR}}/talosconfig
    vars:
      MODE: '{{.MODE | default "auto"}}'
      INSECURE:
        sh: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} get machineconfig &> /dev/null || echo true
      MACHINE_TYPE:
        sh: |-
          talosctl --talosconfig "${TALOS_DIR}/talosconfig" --nodes "${NODE}" get machinetypes --output=jsonpath='{.spec}' 2>/dev/null \
            || basename "$(find "${TALOS_DIR}" -name "${NODE}.yaml" -exec dirname {} \;)"

    env:
      MACHINE_TYPE: '{{.MACHINE_TYPE}}'
      TALOS_SCHEMATIC:
        sh: |-
          curl --silent -X POST --data-binary @{{.TALOS_DIR}}/schematic.yaml https://factory.talos.dev/schematics \
            | jq --raw-output '.id'
    requires:
      vars: [CLUSTER, NODE]
    preconditions:
      - op whoami
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - test -f {{.TALOS_DIR}}/machineconfig.yaml.j2
      - test -f {{.TALOS_DIR}}/{{.MACHINE_TYPE}}/{{.NODE}}.yaml
      - test -f {{.TALOS_DIR}}/schematic.yaml
      - which curl jq minijinja-cli op talosctl

  apply-cluster: ## This isn't working on utility cluster
    desc: Apply the Talos config on all nodes for an existing cluster [CLUSTER=main]
    vars:
      NODES:
        sh: kubectl get nodes --output=jsonpath='{.items[*].metadata.name}' --context {{.CLUSTER}}
    cmds:
      - for: { var: NODES }
        task:  apply-node
        vars:
          NODE: '{{.ITEM}}'
          CLUSTER: "{{.CLUSTER}}"
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - test -f {{.TALOS_DIR}}/talosconfig

  upgrade-node:
    desc: Upgrade Talos on a single node [CLUSTER=main] [NODE=required]
    cmds:
      - task: apply-node
      - talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} upgrade --image={{.TALOS_IMAGE}} --timeout=10m
    vars:
      MACHINE_TYPE:
        sh: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} get machinetypes --output=jsonpath='{.spec}'
      TALOS_IMAGE:
        sh: |-
          talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} get machineconfig --output=jsonpath='{.spec}' \
            | yq '.machine.install.image'
    requires:
      vars: [CLUSTER, NODE]
    preconditions:
      - talosctl --talosconfig {{.TALOS_DIR}}/talosconfig config info
      - talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} get machineconfig
      - which minijinja-cli talosctl yq

  upgrade-k8s:
    desc: Upgrade Kubernetes across the whole cluster [CLUSTER=main]
    cmd: talosctl --nodes {{.RANDOM_CONTROLLER}} upgrade-k8s --to {{.VERSION}}
    vars:
      RANDOM_CONTROLLER:
        sh: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig config info --output yaml | yq --exit-status '.endpoints[0]'
    requires:
      vars: [CLUSTER, VERSION]
    preconditions:
      - talosctl config info
      - talosctl --nodes {{.RANDOM_CONTROLLER}} get machineconfig
      - which jq talosctl

  reset-node:
    desc: Reset Talos on a single node [CLUSTER=main] [NODE=required]
    prompt: Reset Talos node '{{.NODE}}' ... continue?
    cmd: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig reset --nodes {{.NODE}} --graceful=false --reboot #--user-disks-to-wipe u-local-hostpath
    requires:
      vars: [CLUSTER,NODE]
    preconditions:
      - talosctl config info
      # - talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODE}} get machineconfig
      - which talosctl

  reset-cluster:
    desc: Reset Talos across the whole cluster [CLUSTER=main]
    prompt: Reset the Talos cluster ... continue?
    cmd: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig reset --nodes {{.NODES}} --graceful=false --reboot #--user-disks-to-wipe u-local-hostpath
    vars:
      NODES:
        sh: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig config info --output json | jq --join-output '[.nodes[]] | join(",")'
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info
      - talosctl --talosconfig {{.TALOS_DIR}}/talosconfig --nodes {{.NODES}} get machineconfig
      - which jq talosctl

  reboot-node:
    desc: Reboot Talos on a single node [CLUSTER=main] [NODE=required]
    cmds:
      - task: down
      - talosctl --nodes {{.NODE}} reboot --talosconfig {{.TALOS_DIR}}/talosconfig
      - talosctl --nodes {{.NODE}} health --talosconfig {{.TALOS_DIR}}/talosconfig
      - task: up
    requires:
      vars: [CLUSTER, NODE]
    preconditions:
      - talosctl --nodes {{.NODE}} get machineconfig --talosconfig {{.TALOS_DIR}}/talosconfig
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - which talosctl

  reboot-cluster:
    desc: Reboot Talos across the whole cluster [CLUSTER=main]
    prompt: This will reboot all of the cluster nodes. Are you sure you want to continue?
    requires:
      vars: [CLUSTER]
    vars:
      NODES:
        sh: kubectl get nodes --output=jsonpath='{.items[*].metadata.name}' --context {{.CLUSTER}}
    cmds:
      - for: { var: NODES }
        task: reboot-node
        vars:
          NODE: '{{.ITEM}}'
          CLUSTER: "{{.CLUSTER}}"
      - task: :kubernetes:delete-failed-pods
        vars:
          CLUSTER: "{{.CLUSTER}}"
    preconditions:
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - test -f {{.TALOS_DIR}}/talosconfig

  shutdown-cluster:
    desc: Shutdown Talos across the whole cluster [CLUSTER=main]
    prompt: Shutdown the Talos cluster '{{.CLUSTER}}' ... continue?
    cmd: talosctl shutdown --nodes {{.NODES}} --force
    vars:
      NODES:
        sh: kubectl get nodes --output=jsonpath='{.items[*].metadata.name}'
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl --nodes {{.NODES}} get machineconfig --talosconfig {{.TALOS_DIR}}/talosconfig
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - test -f {{.TALOS_DIR}}/talosconfig
      - which talosctl

  kubeconfig:
    desc: Generate the kubeconfig for a Talos cluster [CLUSTER=main]
    cmd: talosctl kubeconfig --nodes {{.TALOS_CONTROLLER}} --force --force-context-name {{.CLUSTER}} {{.CLUSTER_DIR}}
    vars:
      TALOS_CONTROLLER:
        sh: talosctl --talosconfig {{.TALOS_DIR}}/talosconfig config info --output json --talosconfig {{.TALOS_DIR}}/talosconfig | jq --raw-output '.endpoints[]' | shuf -n 1
    requires:
      vars: [CLUSTER]
    preconditions:
      - talosctl config info --talosconfig {{.TALOS_DIR}}/talosconfig
      - test -f {{.TALOS_DIR}}/talosconfig
      - which talosctl

  down:
    internal: true
    cmds:
      - '{{if eq .CLUSTER "main"}}until kubectl wait cephcluster --for=jsonpath=.status.ceph.health=HEALTH_OK --timeout=10m --all --all-namespaces &>/dev/null; do sleep 5; done{{end}}'
      - until kubectl wait jobs --all --all-namespaces --for=condition=complete --timeout=5m &>/dev/null; do sleep 5; done
      - task: :volsync:state-suspend
    preconditions:
      - which kubectl

  up:
    internal: true
    cmds:
      - '{{if eq .CLUSTER "main"}}until kubectl wait cephcluster --for=jsonpath=.status.ceph.health=HEALTH_OK --timeout=10m --all --all-namespaces &>/dev/null; do sleep 5; done{{end}}'
      - until kubectl wait jobs --all --all-namespaces --for=condition=complete --timeout=5m &>/dev/null; do sleep 5; done
      - task: :volsync:state-resume
    preconditions:
      - which kubectl
