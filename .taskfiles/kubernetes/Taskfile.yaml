---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

vars:
  KUBERNETES_RESOURCES_DIR: "{{.ROOT_DIR}}/.taskfiles/kubernetes/resources"

tasks:

  apply-ks:
    desc: Apply a Flux Kustomization resource for a cluster [CLUSTER=main] [PATH=required] [NS=flux-system]
    cmd: >
      flux build --namespace {{.NS}} ks {{base .PATH}}
      --kustomization-file {{.CLUSTER_DIR}}/apps/{{.PATH}}/ks.yaml
      --path {{.CLUSTER_DIR}}/apps/{{.PATH}}
      {{- if contains "not found" .KS }}--dry-run \{{ end }}
      | yq 'with(select(.apiVersion == "kustomize.toolkit.fluxcd.io/v1" and .kind == "Kustomization"); .metadata.namespace = "{{.NS}}")' -
      | kubectl apply --server-side --field-manager=kustomize-controller --filename -
    requires:
      vars: [CLUSTER, PATH]
    vars:
      NS: '{{.NS | default "flux-system"}}'
      KS:
        sh: flux --namespace {{.NS}} get kustomizations {{base .PATH}} 2>&1
    preconditions:
      - test -f {{.CLUSTER_DIR}}/apps/{{.PATH}}/ks.yaml

  browse-pvc:
    desc: Mount a PVC to an temp container [CLUSTER=main] [NS=default] [CLAIM=required]
    interactive: true
    cmd: kubectl browse-pvc --namespace {{.NS}} --image docker.io/library/alpine:latest {{.CLAIM}}
    vars:
      NS: '{{.NS | default "default"}}'
    requires:
      vars: [CLUSTER, CLAIM]
    preconditions:
      - kubectl --namespace {{.NS}} get persistentvolumeclaims {{.CLAIM}}

  node-shell:
    desc: Open a shell to a node [CLUSTER=main] [NODE=required]
    interactive: true
    cmd: kubectl node-shell -n kube-system -x {{.NODE}}
    requires:
      vars: [CLUSTER, NODE]
    preconditions:
      - kubectl get nodes {{.NODE}}
      - kubectl node-shell --version
      - which kubectl

  sync-secrets:
    desc: Sync all ExternalSecrets [CLUSTER=main]
    cmds:
      - for: { var: SECRETS, split: "\n" }
        cmd: kubectl --namespace {{splitList "," .ITEM | first}} annotate externalsecret {{splitList "," .ITEM | last}} force-sync="{{.TS}}" --overwrite  --context {{.CLUSTER}}
    vars:
      TS: '{{now | unixEpoch}}'
      SECRETS:
        sh: kubectl get externalsecret --all-namespaces --no-headers --output=jsonpath='{range .items[*]}{.metadata.namespace},{.metadata.name}{"\n"}{end}' --context {{.CLUSTER}}
    requires:
      vars: [CLUSTER]

  delete-failed-pods:
    desc: Delete pods with a Failed/Pending/Succeeded phase [CLUSTER=main]
    cmds:
      - for:
          matrix:
            PHASE: [Failed, Pending, Succeeded]
        cmd: kubectl --context {{.CLUSTER}} delete pods --field-selector status.phase={{.ITEM.PHASE}} -A --ignore-not-found=true
    requires:
      vars: [CLUSTER]

  reconcile:
    desc: Force update Flux to pull in changes from your Git repository
    cmds:
      - flux get ks --no-header -n flux-system --context {{.CLUSTER}} | awk '{print $1, $2}' | xargs -L1 bash -c 'flux reconcile ks -n flux-system $0 --context {{.CLUSTER}}'
      - flux get ks --all-namespaces --no-header --context {{.CLUSTER}} | awk '{print $1, $2}' | xargs -L1 bash -c 'flux reconcile ks -n $0 $1 --context {{.CLUSTER}}'
    requires:
      vars: [CLUSTER]

  hr-restart:
    desc: Restart all failed Helm Releases
    cmds:
      - kubectl get hr --all-namespaces --context {{.CLUSTER}} | grep False | awk '{print $1, $2}' | xargs -L1 bash -c 'flux suspend hr -n $0 $1 --context {{.CLUSTER}}'
      - kubectl get hr --all-namespaces --context {{.CLUSTER}} | grep False | awk '{print $1, $2}' | xargs -L1 bash -c 'flux resume hr -n $0 $1 --context {{.CLUSTER}}'
    requires:
      vars: [CLUSTER]

  ks-*:
    desc: Suspend or resume Kustomizations [CLUSTER=main]
    cmds:
      - kubectl get ns -o jsonpath='{.items[*].metadata.name}' | xargs -n1 flux {{.STATE}} ks --all --namespace
    vars:
      STATE: '{{index .MATCH 0}}'
    requires:
      vars: [CLUSTER]
    preconditions:
      - '[[ "{{.STATE}}" == "suspend" || "{{.STATE}}" == "resume" ]]'
      - which flux kubectl

  # https://docs.github.com/en/enterprise-cloud@latest/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#upgrading-arc
  upgrade-arc:
    desc: Upgrade the ARC [CLUSTER=main]
    cmds:
      - helm --kube-context {{.CLUSTER}} -n actions-runner-system uninstall home-ops-runner-{{.CLUSTER}} || true
      - helm --kube-context {{.CLUSTER}} -n actions-runner-system uninstall actions-runner-controller || true
      - flux --context {{.CLUSTER}} delete -s -n actions-runner-system helmrelease home-ops-runner-{{.CLUSTER}}  || true
      - flux --context {{.CLUSTER}} delete -s -n actions-runner-system helmrelease actions-runner-controller || true
      - sleep 5
      - flux --context {{.CLUSTER}} -n actions-runner-system reconcile ks actions-runner-controller
      - flux --context {{.CLUSTER}} -n actions-runner-system reconcile ks actions-runner-controller-runners
    requires:
      vars: [CLUSTER]
    preconditions:
      - which flux helm

  flatten:
    desc: Flatten kubectl and talosctl
    cmds:
      - mkdir -p ~/.kube ~/.talos
      - kubectl config view --flatten > ~/.kube/config
      - cp {{.ROOT_DIR}}/talos/utility/talosconfig ~/.talos/config
      # - talosctl config merge {{.ROOT_DIR}}/talos/test/talosconfig --talosconfig ~/.talos/config
      - talosctl config merge {{.ROOT_DIR}}/talos/main/talosconfig --talosconfig ~/.talos/config

  privileged:
    desc: Run a privileged pod
    cmd: |
      echo "Using envsubst: $(which envsubst)"
      kubectl run privileged-{{.node}} -i --rm --image=null \
        --overrides="$(yq {{.KUBERNETES_RESOURCES_DIR}}/privileged-pod.tmpl.yaml -o=json | envsubst)"
    env:
      node: "{{.node}}"
    preconditions:
      - which envsubst
      - test -f {{.KUBERNETES_RESOURCES_DIR}}/privileged-pod.tmpl.yaml
