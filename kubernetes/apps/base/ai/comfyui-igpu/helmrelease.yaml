---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: comfyui
spec:
  chartRef:
    kind: OCIRepository
    name: app-template
  dependsOn: []
  interval: 15m
  values:
    controllers:
      comfyui:
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: ghcr.io/alexkirsz/comfyui
              tag: latest
            env:
              NVIDIA_VISIBLE_DEVICES: "void"  # Disable CUDA
              ONEAPI_DEVICE_SELECTOR: "level_zero:gpu"  # Use Intel GPU via Level Zero
              OCL_ICD_FILENAMES: "intel_level_zero_gpgpu.icd"
              OMP_NUM_THREADS: "16"  # Adjust based on your CPU core count
              OPENBLAS_NUM_THREADS: "16"
              NUMEXPR_NUM_THREADS: "16"
              PYTHONPATH: "/opt/intel/oneapi/python/python-libs"
              LD_LIBRARY_PATH: "/opt/intel/oneapi/lib:/opt/intel/oneapi/compiler/latest/linux/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib64"
            resources:
              claims:
                - name: gpu
              requests:
                cpu: 2000m
                memory: 8Gi
              limits:
                cpu: 4000m
                memory: 16Gi
    defaultPodOptions:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 100
        fsGroup: 100
        fsGroupChangePolicy: "OnRootMismatch"
      resourceClaims:
        - name: gpu
          resourceClaimTemplateName: "${APP}-gpu"
    service:
      app:
        ports:
          http:
            port: 8188
    route:
      app:
        hostnames: ["comfyui.jory.dev"]
        parentRefs:
          - name: envoy-external
            namespace: network
    persistence:
      models:
        enabled: true
        existingClaim: "{{ .Release.Name }}"
        globalMounts:
          - path: /models
            readOnly: false
      outputs:
        enabled: true
        type: persistentVolumeClaim
        size: 50Gi
        accessMode: ReadWriteOnce
        globalMounts:
          - path: /ComfyUI/output
      temp:
        enabled: true
        type: emptyDir
        medium: Memory
        sizeLimit: 2Gi
        globalMounts:
          - path: /tmp